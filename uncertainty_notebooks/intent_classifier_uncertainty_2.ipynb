{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rsilvei/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "# Torch, Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print(torch.__version__)\n",
    "\n",
    "## Embeddings\n",
    "import allennlp\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "## NLP libs\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing SNIPS intent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns = ['phrase', 'intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: AddToPlaylist, Length: 300\n",
      "Intent: BookRestaurant, Length: 300\n",
      "Intent: GetWeather, Length: 300\n",
      "Intent: PlayMusic, Length: 300\n",
      "Intent: RateBook, Length: 300\n",
      "Intent: SearchCreativeWork, Length: 300\n",
      "Intent: SearchScreeningEvent, Length: 300\n"
     ]
    }
   ],
   "source": [
    "for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "               'SearchScreeningEvent']:\n",
    "    with open(\"./2017-06-custom-intent-engines/\" + intent + \"/train_\" + intent + \".json\",\n",
    "              encoding='cp1251') as data_file:\n",
    "        data = json.load(data_file)\n",
    "    print(\"Intent: {}, Length: {}\".format(intent,len(data[intent])))\n",
    "    texts = []\n",
    "    for i in range(len(data[intent])):\n",
    "        text = ''\n",
    "        for j in range(len(data[intent][i]['data'])):\n",
    "            text += data[intent][i]['data'][j]['text']\n",
    "        dataset = dataset.append({'phrase': text, 'intent': intent}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic',\n",
       "       'RateBook', 'SearchCreativeWork', 'SearchScreeningEvent'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.intent.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Cleaning input\n",
    "    text = text.replace(\"'s\",\"\")\n",
    "    text = text.replace(\"â€™s\",\"\")\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"-\",\"\")\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Removing all the stopwords\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in PUNCT)\n",
    "\n",
    "## Lemmatization function based on Spacy Library\n",
    "def lemmatizer_spacy(text):        \n",
    "    sent = []\n",
    "    doc = spacy_en(text)\n",
    "    for word in doc:\n",
    "        if word.lemma_ == \"-PRON-\":\n",
    "            sent.append(word.text)\n",
    "        else:\n",
    "            sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['preproc_text'] = dataset['phrase'].apply(lambda x: transformText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>I want to see a list of the closest cinema's m...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>i want to see a list of the closest cinema movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>What Are the showings for The Natural History ...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>what are the showings for the natural history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>Give me the schedule for Public Stenographer a...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>give me the schedule for public stenographer a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>Is it possible to see Tube at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>is it possible to see tube at the closest movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>I want to see Wenn Lucy springt now at a movie...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>i want to see wenn lucy springt now at a movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>Is Across the Line playing at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>is across the line playing at the closest movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Which animated movies are playing in the neigh...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>which animated movies are playing in the neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Where is They Always Return at Dawn playing</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>where is they always return at dawn playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>What is the movie schedule in the neighborhood</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>what is the movie schedule in the neighborhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>tell me when howling ii your sister is a werew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase                intent  \\\n",
       "2090  I want to see a list of the closest cinema's m...  SearchScreeningEvent   \n",
       "2091  What Are the showings for The Natural History ...  SearchScreeningEvent   \n",
       "2092  Give me the schedule for Public Stenographer a...  SearchScreeningEvent   \n",
       "2093  Is it possible to see Tube at the closest movi...  SearchScreeningEvent   \n",
       "2094  I want to see Wenn Lucy springt now at a movie...  SearchScreeningEvent   \n",
       "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent   \n",
       "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent   \n",
       "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent   \n",
       "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent   \n",
       "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent   \n",
       "\n",
       "                                           preproc_text  \n",
       "2090  i want to see a list of the closest cinema movies  \n",
       "2091  what are the showings for the natural history ...  \n",
       "2092  give me the schedule for public stenographer a...  \n",
       "2093  is it possible to see tube at the closest movi...  \n",
       "2094  i want to see wenn lucy springt now at a movie...  \n",
       "2095  is across the line playing at the closest movi...  \n",
       "2096  which animated movies are playing in the neigh...  \n",
       "2097        where is they always return at dawn playing  \n",
       "2098     what is the movie schedule in the neighborhood  \n",
       "2099  tell me when howling ii your sister is a werew...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNews-vectors-negative300.bin\r\n",
      "crawl-300d-2M.vec\r\n",
      "elmo_2x1024_128_2048cnn_1xhighway_options.json\r\n",
      "elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\r\n",
      "elmo_2x2048_256_2048cnn_1xhighway_options.json\r\n",
      "elmo_2x2048_256_2048cnn_1xhighway_weights.hdf5\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_options.json\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\r\n",
      "glove.42B.300d.txt\r\n",
      "glove.840B.300d.txt\r\n",
      "lid.176.ftz\r\n",
      "wiki-news-300d-1M-subword.txt\r\n",
      "wiki-news-300d-1M.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../vectors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dicionario: 3440\n"
     ]
    }
   ],
   "source": [
    "## Build word vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in dataset.preproc_text:\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(\"Tamanho do dicionario: {}\".format(len(word_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build label vocabulary\n",
    "label_to_ix = {}\n",
    "for label in dataset.intent:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AddToPlaylist': 0,\n",
       " 'BookRestaurant': 1,\n",
       " 'GetWeather': 2,\n",
       " 'PlayMusic': 3,\n",
       " 'RateBook': 4,\n",
       " 'SearchCreativeWork': 5,\n",
       " 'SearchScreeningEvent': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing PyTorch Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe, w2v_weights_path):\n",
    "        self.len = len(dataframe)\n",
    "        self.label_to_ix = {}\n",
    "        self.data = dataframe\n",
    "        self.w2v = w2v = KeyedVectors.load_word2vec_format(w2v_weights_path, binary = True)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phrase = self.data.preproc_text[index]\n",
    "        X, _  = self.get_avg_sentence_vector(phrase)\n",
    "        y = label_to_ix[self.data.intent[index]]\n",
    "        #X.requires_grad = False\n",
    "        #y.requires_grad = False\n",
    "        #blin = X.detach()\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def get_avg_sentence_vector(self, sentence):\n",
    "        featureVec = np.zeros((self.w2v.vector_size), dtype=\"float32\")\n",
    "        nwords = 0\n",
    "        not_found_words = []\n",
    "        for word in sentence.split():\n",
    "            if word in self.w2v.index2word:\n",
    "                nwords = nwords+1\n",
    "                featureVec = np.add(featureVec, self.w2v.get_vector(word))\n",
    "            else:\n",
    "                not_found_words.append(word)\n",
    "        if nwords>0:\n",
    "            featureVec = np.divide(featureVec, nwords)\n",
    "        return featureVec, not_found_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data locations for embeddings\n",
    "elmo_config_key_path = '../../../vectors/elmo_2x4096_512_2048cnn_2xhighway_options.json'\n",
    "elmo_weights_key_path = '../../../vectors/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
    "w2v_weights_path = '../../../vectors/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=dataset.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
    "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2100, 3)\n",
      "TRAIN Dataset: (1680, 3)\n",
      "TEST Dataset: (420, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"FULL Dataset: {}\".format(dataset.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Intents(train_dataset,  w2v_weights_path)\n",
    "testing_set = Intents(test_dataset, w2v_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.66388620e-02,  5.91905378e-02,  2.37630215e-02,  6.19167760e-02,\n",
       "         2.11588549e-03,  2.12198887e-02,  1.03074819e-01, -7.42187500e-02,\n",
       "         4.19116542e-02,  4.27110456e-02, -6.72844797e-02, -8.44997838e-02,\n",
       "        -3.00021693e-02,  1.39024518e-02, -1.12277560e-01,  1.00914851e-01,\n",
       "         9.73205566e-02,  9.18782577e-02,  4.77447510e-02, -1.48383249e-02,\n",
       "        -2.03762054e-02,  2.84016933e-02, -6.75591379e-02, -8.17362498e-03,\n",
       "         5.12152761e-02, -3.71636301e-02, -5.46875000e-02,  5.25037982e-02,\n",
       "        -1.78019202e-03, -1.38888890e-02, -4.50303815e-02,  2.45700404e-02,\n",
       "        -1.99924037e-02,  7.05634207e-02,  7.95084611e-02,  2.36100089e-02,\n",
       "         7.47477189e-02, -3.26605886e-02,  7.50630721e-02,  3.38812917e-02,\n",
       "         9.62320939e-02,  2.27050781e-02,  5.80105260e-02, -4.38944511e-02,\n",
       "        -1.66558158e-02,  4.10291890e-04, -4.19040248e-02,  2.22066250e-02,\n",
       "         7.48697901e-03,  7.97526073e-03, -5.54334857e-02,  3.22672538e-02,\n",
       "         2.35460065e-02, -3.09109166e-02,  4.58102748e-02, -4.84890398e-03,\n",
       "        -2.50278041e-02, -1.03376597e-01, -2.70538330e-02,  7.73111964e-03,\n",
       "         1.14746094e-02,  1.20103627e-01, -5.91634102e-02, -7.22113699e-02,\n",
       "        -8.95182311e-04, -4.86924918e-03, -3.93337682e-02,  5.59743233e-02,\n",
       "        -3.42068151e-02,  1.09714083e-01,  3.19824219e-02,  5.08456752e-02,\n",
       "         8.19023997e-02, -1.94905605e-02, -7.18044713e-02, -9.59676132e-02,\n",
       "         3.11075840e-02,  7.54665807e-02,  3.82520892e-02,  1.38292104e-01,\n",
       "         1.10880537e-02, -8.75634104e-02,  9.00200754e-02, -3.71093750e-02,\n",
       "        -2.18234584e-02, -1.59971453e-02, -9.04541016e-02,  6.98148906e-02,\n",
       "         4.06901032e-04,  6.18082695e-02,  4.21820730e-02,  5.68220345e-03,\n",
       "        -4.68682200e-02, -1.22382268e-01,  1.12982858e-02, -1.71551183e-02,\n",
       "         6.94512278e-02,  5.24817556e-02, -1.35680307e-02, -4.82669398e-02,\n",
       "        -6.60777614e-02, -3.29047292e-02,  2.43665911e-02,  2.56076381e-02,\n",
       "        -6.71115443e-02, -3.94626185e-02, -7.05074742e-02, -5.37245013e-02,\n",
       "         7.37440288e-02, -1.33734811e-02,  1.13118486e-02,  1.89276803e-02,\n",
       "        -2.01755092e-02, -2.64485687e-04,  2.97003854e-02,  3.50613054e-03,\n",
       "         2.12402344e-02, -4.95876744e-02,  9.59201381e-02,  3.92049141e-02,\n",
       "        -7.08821639e-02, -1.71983503e-02, -6.88205287e-02,  4.62515093e-02,\n",
       "        -9.33159739e-02, -4.52473946e-02, -2.81880703e-02, -5.60980886e-02,\n",
       "        -3.31624341e-03,  3.67567269e-03, -2.21218541e-02, -8.51236954e-02,\n",
       "        -6.64062500e-02,  2.73912214e-02,  3.93032506e-02, -6.07757568e-02,\n",
       "         1.15559893e-02,  6.80881087e-03,  2.24270299e-02,  3.46340612e-02,\n",
       "         3.41322161e-02, -6.24321848e-02, -6.33409293e-03, -4.90993932e-02,\n",
       "         8.51508230e-02,  3.46018486e-02, -8.16514716e-03, -6.48871511e-02,\n",
       "        -2.72115078e-02,  3.07888463e-02,  5.83902979e-03,  4.42572683e-02,\n",
       "         2.03179251e-02,  9.90261510e-02, -5.26428223e-04,  1.95380319e-02,\n",
       "        -1.77341029e-02, -6.83593750e-02, -8.87315571e-02, -9.36686173e-02,\n",
       "        -1.29394531e-02,  8.49066824e-02, -5.95389456e-02, -2.76014535e-03,\n",
       "         3.85877825e-02, -1.40150279e-01,  8.62630233e-02, -2.17827689e-02,\n",
       "        -4.22295481e-02,  3.92049141e-02, -1.94227435e-02, -4.63324636e-02,\n",
       "         4.47591161e-03, -5.42602539e-02,  1.06981061e-02, -2.64756940e-02,\n",
       "         6.89493790e-02, -2.35731341e-02,  3.14398855e-02, -5.52978516e-02,\n",
       "        -6.70030415e-02, -1.28326416e-02, -1.62421335e-02,  1.41881304e-02,\n",
       "        -6.24457449e-02, -2.63163242e-02, -9.85378679e-03, -3.70313860e-02,\n",
       "         1.74804688e-01,  5.17985038e-02,  3.36710624e-02,  2.70453561e-02,\n",
       "         6.71115443e-02,  6.10351562e-04,  1.33599178e-03,  8.97894986e-03,\n",
       "         3.42203788e-02, -1.37193464e-02, -8.04850236e-02, -1.51489258e-01,\n",
       "         6.87459335e-02,  5.20290807e-02, -9.28176269e-02, -3.12805176e-04,\n",
       "        -5.63083217e-02, -8.32790788e-03, -4.02018242e-02,  1.24240452e-02,\n",
       "         3.48849818e-02,  1.32293701e-02, -2.84830723e-02,  8.90435092e-03,\n",
       "        -9.52724889e-02, -1.55910915e-02, -1.65581599e-01,  9.89006907e-02,\n",
       "         1.10636391e-01, -1.39973955e-02, -8.48795548e-02,  4.76413313e-03,\n",
       "         3.95880789e-02, -9.65440571e-02, -4.67347056e-02,  2.89815273e-02,\n",
       "         6.11267090e-02, -2.47463658e-02,  2.70631583e-03,  7.09906667e-02,\n",
       "         1.93888340e-02,  3.16704661e-02,  1.18679469e-02, -6.55178502e-02,\n",
       "         6.67317724e-03,  4.07714844e-02,  1.01889715e-01, -4.50303825e-03,\n",
       "        -4.99131950e-03, -3.41084786e-02,  8.96674246e-02, -9.88091342e-03,\n",
       "         4.80041504e-02, -9.27734375e-02, -4.46234830e-03, -9.03320312e-02,\n",
       "        -2.03111442e-03,  4.49761301e-02,  8.76659825e-02,  5.14187291e-02,\n",
       "         4.77091456e-03, -3.49663645e-02, -2.14029942e-02,  2.90798619e-02,\n",
       "         5.97873256e-02,  3.62684466e-02, -7.45985250e-04, -2.14708112e-02,\n",
       "         3.57225211e-03,  7.21655972e-03, -9.47469100e-02,  1.14203561e-02,\n",
       "        -3.11957469e-04, -5.89192696e-02, -1.40787764e-02,  1.42686635e-01,\n",
       "         3.92523855e-02,  1.77137583e-01, -2.88899746e-02, -9.89956316e-03,\n",
       "        -5.24664968e-02,  3.17654088e-02,  5.05438894e-02,  1.31239146e-01,\n",
       "         8.83517787e-02,  9.06507671e-02,  8.45540389e-02, -3.96864153e-02,\n",
       "        -1.99924037e-02, -1.49278432e-01, -4.35655378e-02,  1.14746094e-02,\n",
       "        -4.40809454e-05,  2.35222708e-02,  1.52045358e-02,  7.47918040e-02,\n",
       "         3.91303152e-02,  5.09304460e-03, -1.00314669e-01, -2.14097761e-02,\n",
       "         3.53529193e-02,  2.89306641e-02,  9.35194269e-03,  2.35252380e-02,\n",
       "        -9.97043177e-02,  4.46370430e-02, -2.15521920e-02,  1.08100045e-02,\n",
       "         3.84755656e-02,  1.07930498e-02,  8.26551616e-02, -6.64605051e-02],\n",
       "       dtype=float32), 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set.__getitem__(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, inputdim, \n",
    "                        nclasses, \n",
    "                        nhidden, \n",
    "                        dropout = 0,\n",
    "                        cudaEfficient=True):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        -dropout:    dropout for MLP\n",
    "        \"\"\"\n",
    "        \n",
    "        self.inputdim = inputdim\n",
    "        self.hidden_dim = nhidden\n",
    "        self.dropout = dropout\n",
    "        self.nclasses = nclasses\n",
    "        \n",
    "        if cudaEfficient:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                ).cuda()\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        log_probs = self.model(x)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = training_set.w2v.vector_size\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "NHIDDEN = 512\n",
    "DROPOUT = 0.3\n",
    "model = SimpleMLP(inputdim = INP_DIM ,\n",
    "          nhidden = NHIDDEN,\n",
    "          nclasses = NUM_LABELS,\n",
    "          dropout = DROPOUT, \n",
    "          cudaEfficient = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsilvei/Envs/nlp_new/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0. Loss: 1.942359447479248. Accuracy: 0.47619047619047616%\n",
      "EPOCH -- 1\n",
      "Iteration: 0. Loss: 1.3663665056228638. Accuracy: 80.47619047619048%\n",
      "EPOCH -- 2\n",
      "Iteration: 0. Loss: 0.6236667633056641. Accuracy: 85.71428571428571%\n",
      "EPOCH -- 3\n",
      "Iteration: 0. Loss: 0.2919796407222748. Accuracy: 91.66666666666667%\n",
      "EPOCH -- 4\n",
      "Iteration: 0. Loss: 0.2598581314086914. Accuracy: 93.33333333333333%\n",
      "EPOCH -- 5\n",
      "Iteration: 0. Loss: 0.28362828493118286. Accuracy: 94.76190476190476%\n",
      "EPOCH -- 6\n",
      "Iteration: 0. Loss: 0.08243129402399063. Accuracy: 96.66666666666667%\n",
      "EPOCH -- 7\n",
      "Iteration: 0. Loss: 0.08112271130084991. Accuracy: 97.61904761904762%\n",
      "EPOCH -- 8\n",
      "Iteration: 0. Loss: 0.06717398762702942. Accuracy: 97.38095238095238%\n",
      "EPOCH -- 9\n",
      "Iteration: 0. Loss: 0.06588076800107956. Accuracy: 98.57142857142857%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        ## Step 1 - Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        sent = Variable(sent)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        ## Step 2 - Run forward pass\n",
    "        output = model.forward(sent)\n",
    "        \n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        \n",
    "        ## Step 3 - Compute loss\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        ## Step 4 = Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for sent, label in testing_loader:\n",
    "                sent = Variable(sent)\n",
    "                label = Variable(label)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                output = model.forward(sent)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += label.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_phrase = \"i need to book a restaurant today\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(phrase):\n",
    "    inp, _ = training_set.get_avg_sentence_vector(phrase)\n",
    "    inp = Variable(torch.Tensor(inp))\n",
    "    output = model.forward(inp)\n",
    "\n",
    "    # Get predictions from the maximum value\n",
    "    _, predicted = torch.max(output.data, 0)\n",
    "    pred_label=list(label_to_ix.keys())[list(label_to_ix.values()).index(predicted.item())]\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BookRestaurant'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(input_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AddToPlaylist': 0,\n",
       " 'BookRestaurant': 1,\n",
       " 'GetWeather': 2,\n",
       " 'PlayMusic': 3,\n",
       " 'RateBook': 4,\n",
       " 'SearchCreativeWork': 5,\n",
       " 'SearchScreeningEvent': 6}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Classifier w/ Uncertainty - MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPUncertainty(nn.Module):\n",
    "    def __init__(self, inputdim, \n",
    "                        nclasses, \n",
    "                        nhidden, \n",
    "                        dropout = 0,\n",
    "                        cudaEfficient=True,\n",
    "                        decay = 1e-6):\n",
    "        super(MLPUncertainty, self).__init__()\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        -dropout:    dropout for MLP\n",
    "        \"\"\"\n",
    "        \n",
    "        self.inputdim = inputdim\n",
    "        self.hidden_dim = nhidden\n",
    "        self.dropout = dropout\n",
    "        self.decay = decay\n",
    "        self.nclasses = nclasses\n",
    "        \n",
    "        if cudaEfficient:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                ).cuda()\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        log_probs = self.model(x)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainity_estimate(x, model, iters, l2):\n",
    "    outputs = np.hstack([model(x).data.numpy() for i in trange(iters)])\n",
    "    y_mean = outputs.mean(axis=1)\n",
    "    y_variance = outputs.var(axis=1)\n",
    "    tau = l2 * (1. - model.dropout_p) / (2. * N * model.decay)\n",
    "    y_variance += (1. / tau)\n",
    "    y_std = np.sqrt(y_variance)\n",
    "    return y_mean, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = 'play this music please'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PlayMusic'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0557947 , -0.01062911, -0.0246579 , -0.00250984,  0.00657175,\n",
       "        0.04260978,  0.02417766], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, _ = training_set.get_avg_sentence_vector(phrase)\n",
    "inp = Variable(torch.Tensor(inp))\n",
    "output = model_uncertainty.forward(inp).data.numpy()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_uncertainty = 20\n",
    "lengthscale = 0.01\n",
    "N = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply_test(phrase):\n",
    "    inp, _ = training_set.get_avg_sentence_vector(phrase)\n",
    "    inp = Variable(torch.Tensor(inp))\n",
    "    output = model.forward(inp)\n",
    "    #_, predicted = torch.max(output.data, 0)\n",
    "    output = F.softmax(output, dim=0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<memory at 0x21a0d7348>"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (numpy.ndarray, int), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-493-84031811997d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (numpy.ndarray, int), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "torch.max(y_mean, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply_uncertainty(phrase, iters_uncertainty, lengthscale, N):\n",
    "    outputs = [get_reply_test(phrase).data.numpy() for i in range(iters_uncertainty)]\n",
    "    outs = np.vstack(outputs)\n",
    "    y_mean = outs.mean(axis=0)\n",
    "    y_variance = outs.var(axis=0).sum()\n",
    "    tau = lengthscale * (1. - model_uncertainty.dropout) / (2. * N * model_uncertainty.decay)\n",
    "    y_variance += (1. / tau)\n",
    "    y_std = np.sqrt(y_variance)\n",
    "    predicted = np.argmax(y_mean)\n",
    "    pred_label=list(label_to_ix.keys())[list(label_to_ix.values()).index(predicted)]\n",
    "    return pred_label, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INPUT]: give 5 stars to machine learning book\n",
      "[PREDICTED LABEL]: RateBook\n",
      "[STD DEV]: 0.017623399787340167\n",
      "--------------------------------------------------\n",
      "[INPUT]: christian is going to NIPS\n",
      "[UNCERTAIN] I'm not sure, lot's of variance: Std 0.06501580313801136\n",
      "--------------------------------------------------\n",
      "[INPUT]: play blues songs\n",
      "[PREDICTED LABEL]: PlayMusic\n",
      "[STD DEV]: 0.017245198745267473\n",
      "--------------------------------------------------\n",
      "[INPUT]: today is friday\n",
      "[UNCERTAIN] I'm not sure, lot's of variance: Std 0.13220545720844648\n",
      "--------------------------------------------------\n",
      "[INPUT]: mexicans eat nachos\n",
      "[PREDICTED LABEL]: BookRestaurant\n",
      "[STD DEV]: 0.021249837530390555\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#phrase = 'trump is idiot'\n",
    "x_test = ['trump is idiot',\n",
    "          'when is warm',\n",
    "          'play lady gaga music',\n",
    "          'give 5 stars to machine learning book',\n",
    "          'play reaggae', \n",
    "          'add songs tune in reggae infusions',\n",
    "          'give 5 start to this novel',\n",
    "          'barack obama is cool',\n",
    "          'christian perone is a great software engineer',\n",
    "          'thomas paula is giving unsupervised learning classes',\n",
    "          'paÃ§oca likes candy he is our IT guy'\n",
    "         ]\n",
    "x_test_2 = [\n",
    "    'give 5 stars to machine learning book',\n",
    "    'christian is going to NIPS',\n",
    "    'play blues songs',\n",
    "    'today is friday',\n",
    "    'mexicans eat nachos'\n",
    "]\n",
    "for utt in x_test_2:\n",
    "    predicted, y_std = get_reply_uncertainty(utt, iters_uncertainty, lengthscale, N)\n",
    "    print(\"[INPUT]: {}\".format(utt))\n",
    "    if y_std > 0.05:\n",
    "        print(\"[UNCERTAIN] I'm not sure, lot's of variance: Std {}\".format(y_std))\n",
    "    else:\n",
    "        print(\"[PREDICTED LABEL]: {}\".format(predicted))\n",
    "        print(\"[STD DEV]: {}\".format(y_std))\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AddToPlaylist': 0,\n",
       " 'BookRestaurant': 1,\n",
       " 'GetWeather': 2,\n",
       " 'PlayMusic': 3,\n",
       " 'RateBook': 4,\n",
       " 'SearchCreativeWork': 5,\n",
       " 'SearchScreeningEvent': 6}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>What times will Escape from Hong Kong be showing?</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>what times will escape from hong kong be showing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>most popular song of taco ockerse</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>most popular song of taco ockerse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>rate this current series zero out of 6</td>\n",
       "      <td>RateBook</td>\n",
       "      <td>rate this current series zero out of 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>Put some fifties music on Netflix</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>put some fifties music on netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>What will the weather be here at twelve P.m.?</td>\n",
       "      <td>GetWeather</td>\n",
       "      <td>what will the weather be here at twelve p m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>Can you play some music by Abatte Barihun?</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>can you play some music by abatte barihun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>rate the current essay 1 out of 6 stars</td>\n",
       "      <td>RateBook</td>\n",
       "      <td>rate the current essay 1 out of 6 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>give the current textbook 1 out of 6 stars</td>\n",
       "      <td>RateBook</td>\n",
       "      <td>give the current textbook 1 out of 6 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>Play chant music from 2016 off Pandora.</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>play chant music from 2016 off pandora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>Play a sound track from 1952.</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>play a sound track from 1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>could you give this essay a rating of 1</td>\n",
       "      <td>RateBook</td>\n",
       "      <td>could you give this essay a rating of 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>Play nineties music.</td>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>play nineties music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>Need to see the TV show Brotherly Love</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>need to see the tv show brotherly love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Please look up the show, The Society for the S...</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>please look up the show the society for the st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>I want to watch Uproar in the Studio at the ne...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>i want to watch uproar in the studio at the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>Can I get the movie schedule for ArcLight Holl...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>can i get the movie schedule for arclight holl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>I need to add to the all things post starting ...</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>i need to add to the all things post starting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>what is the forecast for chillier conditions a...</td>\n",
       "      <td>GetWeather</td>\n",
       "      <td>what is the forecast for chillier conditions a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>table for five at Space Aliens Grill &amp; Bar in FM</td>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>table for five at space aliens grill bar in fm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>When is For One Night playing at Loews Cineple...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>when is for one night playing at loews cineple...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase                intent  \\\n",
       "1660  What times will Escape from Hong Kong be showing?  SearchScreeningEvent   \n",
       "1661                  most popular song of taco ockerse             PlayMusic   \n",
       "1662             rate this current series zero out of 6              RateBook   \n",
       "1663                  Put some fifties music on Netflix             PlayMusic   \n",
       "1664      What will the weather be here at twelve P.m.?            GetWeather   \n",
       "1665         Can you play some music by Abatte Barihun?             PlayMusic   \n",
       "1666            rate the current essay 1 out of 6 stars              RateBook   \n",
       "1667         give the current textbook 1 out of 6 stars              RateBook   \n",
       "1668            Play chant music from 2016 off Pandora.             PlayMusic   \n",
       "1669                      Play a sound track from 1952.             PlayMusic   \n",
       "1670            could you give this essay a rating of 1              RateBook   \n",
       "1671                               Play nineties music.             PlayMusic   \n",
       "1672             Need to see the TV show Brotherly Love    SearchCreativeWork   \n",
       "1673  Please look up the show, The Society for the S...    SearchCreativeWork   \n",
       "1674  I want to watch Uproar in the Studio at the ne...  SearchScreeningEvent   \n",
       "1675  Can I get the movie schedule for ArcLight Holl...  SearchScreeningEvent   \n",
       "1676  I need to add to the all things post starting ...         AddToPlaylist   \n",
       "1677  what is the forecast for chillier conditions a...            GetWeather   \n",
       "1678   table for five at Space Aliens Grill & Bar in FM        BookRestaurant   \n",
       "1679  When is For One Night playing at Loews Cineple...  SearchScreeningEvent   \n",
       "\n",
       "                                           preproc_text  \n",
       "1660   what times will escape from hong kong be showing  \n",
       "1661                  most popular song of taco ockerse  \n",
       "1662             rate this current series zero out of 6  \n",
       "1663                  put some fifties music on netflix  \n",
       "1664       what will the weather be here at twelve p m   \n",
       "1665          can you play some music by abatte barihun  \n",
       "1666            rate the current essay 1 out of 6 stars  \n",
       "1667         give the current textbook 1 out of 6 stars  \n",
       "1668            play chant music from 2016 off pandora   \n",
       "1669                      play a sound track from 1952   \n",
       "1670            could you give this essay a rating of 1  \n",
       "1671                               play nineties music   \n",
       "1672             need to see the tv show brotherly love  \n",
       "1673  please look up the show the society for the st...  \n",
       "1674  i want to watch uproar in the studio at the ne...  \n",
       "1675  can i get the movie schedule for arclight holl...  \n",
       "1676  i need to add to the all things post starting ...  \n",
       "1677  what is the forecast for chillier conditions a...  \n",
       "1678     table for five at space aliens grill bar in fm  \n",
       "1679  when is for one night playing at loews cineple...  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Classifier w/ Uncertainty - Deep Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_new)",
   "language": "python",
   "name": "nlp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
