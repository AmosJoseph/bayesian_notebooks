{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rsilvei/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "\n",
    "# Torch, Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print(torch.__version__)\n",
    "\n",
    "## Embeddings\n",
    "import allennlp\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "## NLP libs\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing SNIPS intent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns = ['phrase', 'intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: AddToPlaylist, Length: 300\n",
      "Intent: BookRestaurant, Length: 300\n",
      "Intent: GetWeather, Length: 300\n",
      "Intent: PlayMusic, Length: 300\n",
      "Intent: RateBook, Length: 300\n",
      "Intent: SearchCreativeWork, Length: 300\n",
      "Intent: SearchScreeningEvent, Length: 300\n"
     ]
    }
   ],
   "source": [
    "for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "               'SearchScreeningEvent']:\n",
    "    with open(\"./2017-06-custom-intent-engines/\" + intent + \"/train_\" + intent + \".json\",\n",
    "              encoding='cp1251') as data_file:\n",
    "        data = json.load(data_file)\n",
    "    print(\"Intent: {}, Length: {}\".format(intent,len(data[intent])))\n",
    "    texts = []\n",
    "    for i in range(len(data[intent])):\n",
    "        text = ''\n",
    "        for j in range(len(data[intent][i]['data'])):\n",
    "            text += data[intent][i]['data'][j]['text']\n",
    "        dataset = dataset.append({'phrase': text, 'intent': intent}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic',\n",
       "       'RateBook', 'SearchCreativeWork', 'SearchScreeningEvent'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.intent.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=False, do_stem=False):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Cleaning input\n",
    "    text = text.replace(\"'s\",\"\")\n",
    "    text = text.replace(\"â€™s\",\"\")\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"-\",\"\")\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Removing all the stopwords\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    if (do_stem==True):\n",
    "        # Stemming\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    return text\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in PUNCT)\n",
    "\n",
    "## Lemmatization function based on Spacy Library\n",
    "def lemmatizer_spacy(text):        \n",
    "    sent = []\n",
    "    doc = spacy_en(text)\n",
    "    for word in doc:\n",
    "        if word.lemma_ == \"-PRON-\":\n",
    "            sent.append(word.text)\n",
    "        else:\n",
    "            sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['preproc_text'] = dataset['phrase'].apply(lambda x: transformText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>I want to see a list of the closest cinema's m...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>i want to see a list of the closest cinema movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>What Are the showings for The Natural History ...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>what are the showings for the natural history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>Give me the schedule for Public Stenographer a...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>give me the schedule for public stenographer a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>Is it possible to see Tube at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>is it possible to see tube at the closest movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>I want to see Wenn Lucy springt now at a movie...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>i want to see wenn lucy springt now at a movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>Is Across the Line playing at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>is across the line playing at the closest movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Which animated movies are playing in the neigh...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>which animated movies are playing in the neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Where is They Always Return at Dawn playing</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>where is they always return at dawn playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>What is the movie schedule in the neighborhood</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>what is the movie schedule in the neighborhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>tell me when howling ii your sister is a werew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase                intent  \\\n",
       "2090  I want to see a list of the closest cinema's m...  SearchScreeningEvent   \n",
       "2091  What Are the showings for The Natural History ...  SearchScreeningEvent   \n",
       "2092  Give me the schedule for Public Stenographer a...  SearchScreeningEvent   \n",
       "2093  Is it possible to see Tube at the closest movi...  SearchScreeningEvent   \n",
       "2094  I want to see Wenn Lucy springt now at a movie...  SearchScreeningEvent   \n",
       "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent   \n",
       "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent   \n",
       "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent   \n",
       "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent   \n",
       "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent   \n",
       "\n",
       "                                           preproc_text  \n",
       "2090  i want to see a list of the closest cinema movies  \n",
       "2091  what are the showings for the natural history ...  \n",
       "2092  give me the schedule for public stenographer a...  \n",
       "2093  is it possible to see tube at the closest movi...  \n",
       "2094  i want to see wenn lucy springt now at a movie...  \n",
       "2095  is across the line playing at the closest movi...  \n",
       "2096  which animated movies are playing in the neigh...  \n",
       "2097        where is they always return at dawn playing  \n",
       "2098     what is the movie schedule in the neighborhood  \n",
       "2099  tell me when howling ii your sister is a werew...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNews-vectors-negative300.bin\r\n",
      "crawl-300d-2M.vec\r\n",
      "elmo_2x1024_128_2048cnn_1xhighway_options.json\r\n",
      "elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\r\n",
      "elmo_2x2048_256_2048cnn_1xhighway_options.json\r\n",
      "elmo_2x2048_256_2048cnn_1xhighway_weights.hdf5\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_options.json\r\n",
      "elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\r\n",
      "glove.42B.300d.txt\r\n",
      "glove.840B.300d.txt\r\n",
      "lid.176.ftz\r\n",
      "wiki-news-300d-1M-subword.txt\r\n",
      "wiki-news-300d-1M.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../vectors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dicionario: 3440\n"
     ]
    }
   ],
   "source": [
    "## Build word vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in dataset.preproc_text:\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(\"Tamanho do dicionario: {}\".format(len(word_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build label vocabulary\n",
    "label_to_ix = {}\n",
    "for label in dataset.intent:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AddToPlaylist': 0,\n",
       " 'BookRestaurant': 1,\n",
       " 'GetWeather': 2,\n",
       " 'PlayMusic': 3,\n",
       " 'RateBook': 4,\n",
       " 'SearchCreativeWork': 5,\n",
       " 'SearchScreeningEvent': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing PyTorch Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe, w2v_weights_path):\n",
    "        self.len = len(dataframe)\n",
    "        self.label_to_ix = {}\n",
    "        self.data = dataframe\n",
    "        self.w2v = w2v = KeyedVectors.load_word2vec_format(w2v_weights_path, binary = True)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phrase = self.data.preproc_text[index]\n",
    "        X, _  = self.get_avg_sentence_vector(phrase)\n",
    "        y = label_to_ix[self.data.intent[index]]\n",
    "        #X.requires_grad = False\n",
    "        #y.requires_grad = False\n",
    "        #blin = X.detach()\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def get_avg_sentence_vector(self, sentence):\n",
    "        featureVec = np.zeros((self.w2v.vector_size), dtype=\"float32\")\n",
    "        nwords = 0\n",
    "        not_found_words = []\n",
    "        for word in sentence.split():\n",
    "            if word in self.w2v.index2word:\n",
    "                nwords = nwords+1\n",
    "                featureVec = np.add(featureVec, self.w2v.get_vector(word))\n",
    "            else:\n",
    "                not_found_words.append(word)\n",
    "        if nwords>0:\n",
    "            featureVec = np.divide(featureVec, nwords)\n",
    "        return featureVec, not_found_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data locations for embeddings\n",
    "elmo_config_key_path = '../../../vectors/elmo_2x4096_512_2048cnn_2xhighway_options.json'\n",
    "elmo_weights_key_path = '../../../vectors/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
    "w2v_weights_path = '../../../vectors/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=dataset.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
    "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2100, 3)\n",
      "TRAIN Dataset: (1680, 3)\n",
      "TEST Dataset: (420, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"FULL Dataset: {}\".format(dataset.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Intents(train_dataset,  w2v_weights_path)\n",
    "testing_set = Intents(test_dataset, w2v_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set.__getitem__(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, inputdim, \n",
    "                        nclasses, \n",
    "                        nhidden, \n",
    "                        dropout = 0,\n",
    "                        cudaEfficient=True):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        -dropout:    dropout for MLP\n",
    "        \"\"\"\n",
    "        \n",
    "        self.inputdim = inputdim\n",
    "        self.hidden_dim = nhidden\n",
    "        self.dropout = dropout\n",
    "        self.nclasses = nclasses\n",
    "        \n",
    "        if cudaEfficient:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                ).cuda()\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.inputdim, nhidden),\n",
    "                nn.Dropout(p=self.dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(nhidden, self.nclasses),\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        log_probs = self.model(x)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = training_set.w2v.vector_size\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "NHIDDEN = 512\n",
    "DROPOUT = 0.3\n",
    "model = SimpleMLP(inputdim = INP_DIM ,\n",
    "          nhidden = NHIDDEN,\n",
    "          nclasses = NUM_LABELS,\n",
    "          dropout = DROPOUT, \n",
    "          cudaEfficient = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsilvei/Envs/nlp_new/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0. Loss: 1.9529027938842773. Accuracy: 20.714285714285715%\n",
      "EPOCH -- 1\n",
      "Iteration: 0. Loss: 1.3044142723083496. Accuracy: 77.61904761904762%\n",
      "EPOCH -- 2\n",
      "Iteration: 0. Loss: 0.576018750667572. Accuracy: 87.38095238095238%\n",
      "EPOCH -- 3\n",
      "Iteration: 0. Loss: 0.25380849838256836. Accuracy: 91.9047619047619%\n",
      "EPOCH -- 4\n",
      "Iteration: 0. Loss: 0.13997235894203186. Accuracy: 91.66666666666667%\n",
      "EPOCH -- 5\n",
      "Iteration: 0. Loss: 0.0978354662656784. Accuracy: 96.19047619047619%\n",
      "EPOCH -- 6\n",
      "Iteration: 0. Loss: 0.09859947860240936. Accuracy: 96.42857142857143%\n",
      "EPOCH -- 7\n",
      "Iteration: 0. Loss: 0.055040061473846436. Accuracy: 97.38095238095238%\n",
      "EPOCH -- 8\n",
      "Iteration: 0. Loss: 0.11213701218366623. Accuracy: 98.33333333333333%\n",
      "EPOCH -- 9\n",
      "Iteration: 0. Loss: 0.09071548283100128. Accuracy: 98.0952380952381%\n",
      "EPOCH -- 10\n",
      "Iteration: 0. Loss: 0.041426051408052444. Accuracy: 98.57142857142857%\n",
      "EPOCH -- 11\n",
      "Iteration: 0. Loss: 0.07044611126184464. Accuracy: 99.04761904761905%\n",
      "EPOCH -- 12\n",
      "Iteration: 0. Loss: 0.04122191667556763. Accuracy: 99.04761904761905%\n",
      "EPOCH -- 13\n",
      "Iteration: 0. Loss: 0.022217005491256714. Accuracy: 99.04761904761905%\n",
      "EPOCH -- 14\n",
      "Iteration: 0. Loss: 0.03328843414783478. Accuracy: 99.52380952380952%\n",
      "EPOCH -- 15\n",
      "Iteration: 0. Loss: 0.04262634366750717. Accuracy: 99.28571428571429%\n",
      "EPOCH -- 16\n",
      "Iteration: 0. Loss: 0.08449859917163849. Accuracy: 99.52380952380952%\n",
      "EPOCH -- 17\n",
      "Iteration: 0. Loss: 0.020350055769085884. Accuracy: 99.52380952380952%\n",
      "EPOCH -- 18\n",
      "Iteration: 0. Loss: 0.04676220193505287. Accuracy: 99.28571428571429%\n",
      "EPOCH -- 19\n",
      "Iteration: 0. Loss: 0.0221561249345541. Accuracy: 99.28571428571429%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 20\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        ## Step 1 - Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        sent = Variable(sent)\n",
    "        label = Variable(label)\n",
    "        \n",
    "        ## Step 2 - Run forward pass\n",
    "        output = model.forward(sent)\n",
    "        \n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        \n",
    "        ## Step 3 - Compute loss\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        ## Step 4 = Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            \n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for sent, label in testing_loader:\n",
    "                sent = Variable(sent)\n",
    "                label = Variable(label)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                output = model.forward(sent)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += label.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_phrase = \"i need to book a restaurant today\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(phrase):\n",
    "    inp, _ = training_set.get_avg_sentence_vector(phrase)\n",
    "    inp = Variable(torch.Tensor(inp))\n",
    "    output = model.forward(inp)\n",
    "\n",
    "    # Get predictions from the maximum value\n",
    "    _, predicted = torch.max(output.data, 0)\n",
    "    pred_label=list(label_to_ix.keys())[list(label_to_ix.values()).index(predicted.item())]\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BookRestaurant'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(input_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AddToPlaylist': 0,\n",
       " 'BookRestaurant': 1,\n",
       " 'GetWeather': 2,\n",
       " 'PlayMusic': 3,\n",
       " 'RateBook': 4,\n",
       " 'SearchCreativeWork': 5,\n",
       " 'SearchScreeningEvent': 6}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_new)",
   "language": "python",
   "name": "nlp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
